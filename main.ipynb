{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "label_list = []\n",
    "for i in range(1,901):\n",
    "    name = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/pencilCase/test'\n",
    "    name = name + str(i) + '.jpg'\n",
    "    image_list.append(name)\n",
    "    label_list.append([1,0,0])\n",
    "for i in range(1,901):\n",
    "    name = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/tissue/tissue'\n",
    "    name = name + str(i) + '.jpg'\n",
    "    image_list.append(name)\n",
    "    label_list.append([0,1,0])\n",
    "for i in range(1,901):\n",
    "    name = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/watch/watch'\n",
    "    name = name + str(i) + '.jpg'\n",
    "    image_list.append(name)\n",
    "    label_list.append([0,0,1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_list_image(input):\n",
    "    return [cv.imread(input[x], cv.IMREAD_GRAYSCALE) for x in range(2700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack(_read_list_image(image_list))\n",
    "label = np.array(label_list, dtype=np.float32)#label float화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.reshape(img, shape=[-1,2304])\n",
    "img = tf.to_float(img,name='ToFloat')#img float화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((img,label))\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(5000)\n",
    "dataset = dataset.batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "image_stack, label_stack = iterator.get_next()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(iterator.initializer)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sess.run(next_element)#아래의 placeholder가 씹힘 주의할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81.  90.  82. ... 117. 117. 117.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape = [None, 2304])# 48 * 48 size image\n",
    "y = tf.placeholder(dtype=tf.float32, shape = [None, 3])# pencilcase, tissue, watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,48,48,1]) #벡터화된 이미지 값을 매트릭스화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape): #weight 정의 함수. kernel, model등에 쓰임\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape): #bias 정의 함수, 위와 마찬가지로 쓰임\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(x, kernel): #합성곱을 한칸씩 이동해서 하며 이를 통해 만들어진 feature map의 크기가 같음\n",
    "    return tf.nn.conv2d(x, kernel, strides=[1,1,1,1], padding='SAME') #padding='SAME' 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(x): # 2x2 를 1x1로 maxpooling 하는 함수\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_1 = weight_variable([5,5,1,32]) # 1개의 input에 대해서 5x5의 커널을 32개의 채널로 만듬\n",
    "b_conv_1 = bias_variable([32]) #커널의 채널수에 맞는 bias 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = tf.nn.relu(convolution(x_image, kernel_1) + b_conv_1) #합성곱 후 활성함수에 넣은 activation map\n",
    "pool_1 = pooling(conv_1) #activation map maxpooling으로 간소화 48x48 -> 24x24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = weight_variable([5,5,32,64]) # 32개의 input에 대해서 5x5의 커널을 64개의 채널로 만듬\n",
    "b_conv_2 = bias_variable([64]) #커널의 채널수에 맞는 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2 = tf.nn.relu(convolution(pool_1, kernel_2) + b_conv_2)\n",
    "pool_2 = pooling(conv_2) # 위 행위 반복 24x24 -> 12x12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_3 = weight_variable([5,5,64,128])\n",
    "b_conv_3 = bias_variable([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3 = tf.nn.relu(convolution(pool_2, kernel_3) + b_conv_3)\n",
    "pool_3 = pooling(conv_3)# 12x12 -> 6x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fc1 = weight_variable([6*6*128, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "pool_flat = tf.reshape(pool_3, [-1, 6*6*128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_fc1 = tf.nn.relu(tf.matmul(pool_flat, w_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_dropout = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fc2 = weight_variable([1024,3])\n",
    "b_fc2 = bias_variable([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_dropout, w_fc2) + b_fc2) #softmax까지 써서 최종적인 판단 결과 도출, 이놈이 hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(iterator.initializer)#반드시 변수 initializer해줘야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  0  :  0.4\n",
      "step  25  :  0.5\n",
      "step  50  :  0.3\n",
      "step  75  :  0.1\n",
      "step  100  :  0.25\n",
      "step  125  :  0.4\n",
      "step  150  :  0.25\n",
      "step  175  :  0.4\n",
      "step  200  :  0.1\n",
      "step  225  :  0.2\n",
      "step  250  :  0.55\n",
      "step  275  :  0.4\n",
      "step  300  :  0.3\n",
      "step  325  :  0.25\n",
      "step  350  :  0.15\n",
      "step  375  :  0.25\n",
      "step  400  :  0.5\n",
      "step  425  :  0.5\n",
      "step  450  :  0.2\n",
      "step  475  :  0.3\n",
      "step  500  :  0.45\n",
      "step  525  :  0.5\n",
      "step  550  :  0.45\n",
      "step  575  :  0.3\n",
      "step  600  :  0.35\n",
      "step  625  :  0.2\n",
      "step  650  :  0.35\n",
      "step  675  :  0.35\n",
      "step  700  :  0.6\n",
      "step  725  :  0.4\n",
      "step  750  :  0.25\n",
      "step  775  :  0.35\n",
      "step  800  :  0.45\n",
      "step  825  :  0.4\n",
      "step  850  :  0.45\n",
      "step  875  :  0.3\n",
      "step  900  :  0.15\n",
      "step  925  :  0.35\n",
      "step  950  :  0.45\n",
      "step  975  :  0.4\n",
      "step  1000  :  0.2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1001):\n",
    "    x_data, y_data = sess.run(next_element)    \n",
    "    if i%25 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x:x_data, y:y_data, keep_prob:1.0})\n",
    "        print(\"step \",i,\" : \",train_accuracy)\n",
    "    sess.run(train_step, feed_dict={x:x_data, y:y_data, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19. 20. 21. ...  3.  3. 11.]\n"
     ]
    }
   ],
   "source": [
    "#path = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/pencilCase/test1500.jpg'\n",
    "#path = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/tissue/tissue910.jpg'\n",
    "path = 'C:/Users/sfsfk/Desktop/develope/tensorflow/ssuface/data/watch/watch905.jpg'\n",
    "\n",
    "test_x = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "test_x = tf.reshape(test_x, shape=[-1,2304])\n",
    "test_x = tf.to_float(test_x,name='ToFloat')\n",
    "test_x = sess.run(test_x)#tensor object는 sess.run하면 본래의 자료형이 튀어나옴\n",
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "1.0\n",
      "[0. 1. 0.]\n",
      "0.0\n",
      "[0. 0. 1.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_y1 = [[1,0,0]]\n",
    "test_y1 = np.array(test_y1, dtype=np.float32)\n",
    "pred = sess.run(accuracy, feed_dict={x:test_x, y:test_y1, keep_prob:1.0})\n",
    "print(test_y1[0])\n",
    "print(pred)\n",
    "\n",
    "test_y2 = [[0,1,0]]\n",
    "test_y2 = np.array(test_y2, dtype=np.float32)\n",
    "pred = sess.run(accuracy, feed_dict={x:test_x, y:test_y2, keep_prob:1.0})\n",
    "print(test_y2[0])\n",
    "print(pred)\n",
    "\n",
    "test_y3 = [[0,0,1]]\n",
    "test_y3 = np.array(test_y3, dtype=np.float32)\n",
    "pred = sess.run(accuracy, feed_dict={x:test_x, y:test_y3, keep_prob:1.0})\n",
    "print(test_y3[0])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
