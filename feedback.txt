2019.1.30
***
name1, name2, name3 ... 등으로 연속해서 string + int 로 이름을 지어야 할 때

name = 'fileName'
num = 1
name = name + str(num)

으로 가능 (파일 입출력 예 savaFile.py 참고)

***
np.array가 훨씬 빠른 연산속도(내부가 c로 작동해서?)
cv.imread를 통해 얻어진 2차원 list를 3차원 list로 병합한 새로운 list가 필요할 때
np.stack을 통해 차원을 올릴 수 있다. -> list = np.stack([list1, list2, list3])
근데 여기서는 2차원 list 1847을 np.stack을 이용해 병합해야함. 즉, np.stack([list1, list2, list3 ... list1847])
->[list1, list2, list3, .. list1847]을 반환하는 함수를 정의

    def func(input):
        return [cv.imread(input[x]) for x int range(1847)]  

    list = np.stack(func(image_address_list))
    사전에 list로 정리해둔 이미지 주소를 매개변수로 주고 순서대로 경로를 읽어와 imread의 
    매개변수로 전달해 최종적으로 원하는 이미지의 2차원 list들을 반환해 3차원 list로 병합한다

단순 list에 계속 원소들을 넣어야 할 때
-> list.append(element) 병렬적으로 계속 추가된다.
(makeFileList.py 참고)

TODO:
    1. cnn 모델 만들어서 기본모델 작동여부 확인
    2. 데이터 전처리 과정에서 반복문 반복 횟수 영상마다 다를 것임으로 data/class 아래에 이에 필요한 txt파일 만들어서 자동화 준비
    3. 모델 저장 및 불러오는 방법 알아보기
    4. .py 실행 방법 알아보기
    5. 다른 파일 어떻게 불러오는지 알아보기
    6. 구글 cloudml 사용 염두
    7. 학습중 cost 그래프로 보는거 알아보기


2019.1.31
***
cv.IMREAD_GRAYSCALE로 읽어서 용량도 줄이고 학습모델의 shape도 통일!
next_element로 dataset에 넣은 정보를 그냥 가져오면
ex) batch = next_element
그냥 텐서 오브젝트가 던져짐으로 
-> batch = sess.run(next_element)해서 feeding 하도록 하자

***
sess.run(tf.global_variables_initializer())
sess.run(iterator.initializer)
variable 과 iterator등 학습 전 반드시 initializer을 하도록 하자 안하면 안돌아감 ㅡㅡ

***
계속 내가 feed하려는 데이터랑 학습 모델이 요구하는 float의 형 일치가 이뤄지지 않는다.
data = tf.to_float(data, name='ToFloat')로 바꿨는데도 안댐 ㅡㅡ
근데 print(type(data))로 보면 <class 'tensorflow.python.framework.ops.Tensor'>이렇게 나오는데
원하는 대로 변화가 된건지는 의문

TODO:
    기존 mnist등등의 기본 예제에서 불러온 자료가 어떤 타입인지 보고 그에 맞춰보자


2019.2.10
***
feed_dict의 x,y는 내가 정의한 placeholder로 여기에 맞는 자료를 집어넣어야만 한다
따라서 이번경우에는 반드시 float형 [?,2304]의 shape을 가지는 자료를 넣어야만 한다
착각하기 쉬우니 주의!

***
tensor object는 sess.run(tensor_object)하면 본래의 자료를 던져준다
x_data , y_data = sess.run(next_element)는 각각 x 와 y에 내가 정한만큼 batch해 준다
그리고 이를 바로 feed_dict={x:x_data, y:y_data}해줘야 한다.
왜냐하면 x_data, y_data의 shape이 [batch_size,2304] , [batch_size,3]으로 이미 place holder에
맞게 나오기 때문

***
검증에 필요한 모델은 fancy_softmax.ipynb에서 hypothesis부분으로 sotfmax의 반환이다

근데 cnn에서는 y_conv부분으로 마찬가지로 softmax의 반환인데 input으로 cnn처리된 1024
배열을 필요로 한다. 즉, 2304의 이미지 벡터로는 결과를 볼 수 없다

TODO:
    CNN모델에서 학습된 모델을 테스트하는 방법
    dataset에서 train과 test데이터 셋 분리하는 방법


2019.2.11
***
rank -> 차원
shape -> 가장 안쪽 차원(우측)부터 element의 수
axis -> 가장 바깥쪽 차원부터 0으로 시작해서 예를들어 rank가 4라면 가장 안쪽 axis는 3이됨
+ 가장 안쪽의 axis는 -1이라고도 표현(slicing 할 때랑 같은 느낌)

***
matrix의 곱은 matmul을 사용해야 우리가 생각하는 결과가 나옴
그냥 곱하기 하면 걍 이상한 값 나오니 주의

***
braodcasting을 통해 다른 shape을 extend하여 어거지로 연산을 가능하게함

***
reduce_mean을 할 때 axis에 따라서 다르게 연산이 됨
ex)x = ( [1. 2.]
           [3. 4.] )

    tf.reduce_mean(x, axis=0).eval() -> [2., 3.]
    tf.reduce_mean(x, axis=1).eval() -> [1.5, 3.5]

축 없이 reduce_mean을 하면 모든 원소의 평균이다. 예제의 경우 2.5